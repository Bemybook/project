# project2
Technologies used were:-
->Ionic Platform(To run web application)
->Angular.js
->Cordova
->Node.js
->Visual Studio Code

METHODOLOGY

![image](https://user-images.githubusercontent.com/83057352/120181426-ac4bdd00-c22a-11eb-8404-c280682c8777.png)



Methodology used were:-
SCREEN 1: Our app name and introduction is given.
SCREEN 2: Login page. At present we had given only login for 4 users ( Amogha, srikala, swati and sakshi). Later we will be creating a Register system through Firebase Connection.
SCREEN 3 : After Login we have Finger authentication which we will be doing late

SCREEN 4: Folder page is displayed. Here we gave 2 options. Either to upload image from library or use take to take image.
SCREEN5: Text is extracted from image within seconds using Google OCR and speech is produced using Google Text to Speech API.
We had made use of GOOGLE SPEECH RECOGNITION MODULE to take voice input from the user.
As we had mentioned in the previous update that we will be working on the look and feel of the app, so we have designed the front end part of the application.

Below are few snapshots on  how the front end part of the application will look like:-

Screen 1: INTRODUCTION OF THE APP AND GOOGLE SPEECH IS ASKING USER TO TELL THE NAME
![image](https://user-images.githubusercontent.com/83057352/120181479-bff74380-c22a-11eb-921c-f6f193d69cb7.png)

Screen 2 :FOLDER SCREEN AND APP GIVING OPTION UPLOAD IMAGE FROM LIBRARY OR TAKE A PICTURE
![image](https://user-images.githubusercontent.com/83057352/120181496-c5548e00-c22a-11eb-996a-8d62d35445bc.png)

Screen 3:LOAD IMAGE FROM LIBRARY
![image](https://user-images.githubusercontent.com/83057352/120181629-f7fe8680-c22a-11eb-9e6d-e4a329592b23.png)

Screen 4 :EXTRACTED TEXT AND OUTPUTS THE VOICE 
![image](https://user-images.githubusercontent.com/83057352/120181690-0a78c000-c22b-11eb-9e04-46be727908b3.png)

